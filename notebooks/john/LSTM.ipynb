{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176e9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fb2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"../../data/processed/historical_kba_data.parquet\"\n",
    "df = pd.read_parquet(storage_path, engine='fastparquet')\n",
    "df[\"ts_key_size\"] = df.groupby('ts_key')['ts_key'].transform('size')\n",
    "\n",
    "# FIlter ts_keys with at least 12 entries\n",
    "df = df[df['ts_key_size'] >= 12].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8312f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OEM",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "drive_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "ts_key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ts_key_size",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0beb98f9-ef08-4bda-b209-5221e9b06cc7",
       "rows": [
        [
         "1745",
         "ALFA ROMEO",
         "GIULIA",
         "All_Wheel_Drive",
         "79.0",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_All_Wheel_Drive",
         "94"
        ],
        [
         "2094",
         "ALFA ROMEO",
         "GIULIA",
         "Convertibles",
         "0.0",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Convertibles",
         "94"
        ],
        [
         "698",
         "ALFA ROMEO",
         "GIULIA",
         "Diesel",
         "9.0",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Diesel",
         "94"
        ],
        [
         "1047",
         "ALFA ROMEO",
         "GIULIA",
         "Electric_BEV",
         "0.0",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Electric_BEV",
         "94"
        ],
        [
         "1396",
         "ALFA ROMEO",
         "GIULIA",
         "Hybrid",
         "0.0",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Hybrid",
         "94"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OEM</th>\n",
       "      <th>Model</th>\n",
       "      <th>drive_type</th>\n",
       "      <th>Value</th>\n",
       "      <th>Date</th>\n",
       "      <th>ts_key</th>\n",
       "      <th>ts_key_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>ALFA ROMEO</td>\n",
       "      <td>GIULIA</td>\n",
       "      <td>All_Wheel_Drive</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_All_Wheel_Drive</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>ALFA ROMEO</td>\n",
       "      <td>GIULIA</td>\n",
       "      <td>Convertibles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Convertibles</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>ALFA ROMEO</td>\n",
       "      <td>GIULIA</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Diesel</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>ALFA ROMEO</td>\n",
       "      <td>GIULIA</td>\n",
       "      <td>Electric_BEV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Electric_BEV</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>ALFA ROMEO</td>\n",
       "      <td>GIULIA</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Hybrid</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OEM   Model       drive_type  Value       Date  \\\n",
       "1745  ALFA ROMEO  GIULIA  All_Wheel_Drive   79.0 2022-10-31   \n",
       "2094  ALFA ROMEO  GIULIA     Convertibles    0.0 2022-10-31   \n",
       "698   ALFA ROMEO  GIULIA           Diesel    9.0 2022-10-31   \n",
       "1047  ALFA ROMEO  GIULIA     Electric_BEV    0.0 2022-10-31   \n",
       "1396  ALFA ROMEO  GIULIA           Hybrid    0.0 2022-10-31   \n",
       "\n",
       "                                 ts_key  ts_key_size  \n",
       "1745  ALFA ROMEO_GIULIA_All_Wheel_Drive           94  \n",
       "2094     ALFA ROMEO_GIULIA_Convertibles           94  \n",
       "698            ALFA ROMEO_GIULIA_Diesel           94  \n",
       "1047     ALFA ROMEO_GIULIA_Electric_BEV           94  \n",
       "1396           ALFA ROMEO_GIULIA_Hybrid           94  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50835160",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Date','ts_key', 'Value']\n",
    "\n",
    "df = df[columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cbaee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "ts_key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0ac9aacc-2049-46a8-b667-88b9c73e7082",
       "rows": [
        [
         "1745",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_All_Wheel_Drive",
         "79.0"
        ],
        [
         "2094",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Convertibles",
         "0.0"
        ],
        [
         "698",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Diesel",
         "9.0"
        ],
        [
         "1047",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Electric_BEV",
         "0.0"
        ],
        [
         "1396",
         "2022-10-31 00:00:00",
         "ALFA ROMEO_GIULIA_Hybrid",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ts_key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_All_Wheel_Drive</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Convertibles</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Diesel</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Electric_BEV</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>ALFA ROMEO_GIULIA_Hybrid</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                             ts_key  Value\n",
       "1745 2022-10-31  ALFA ROMEO_GIULIA_All_Wheel_Drive   79.0\n",
       "2094 2022-10-31     ALFA ROMEO_GIULIA_Convertibles    0.0\n",
       "698  2022-10-31           ALFA ROMEO_GIULIA_Diesel    9.0\n",
       "1047 2022-10-31     ALFA ROMEO_GIULIA_Electric_BEV    0.0\n",
       "1396 2022-10-31           ALFA ROMEO_GIULIA_Hybrid    0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5713278c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ts_key.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c453d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Aggregate duplicates by summing values\n",
    "pivot_df = df.groupby(['Date', 'ts_key'])['Value'].sum().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a489351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08589886",
   "metadata": {},
   "source": [
    "# LSTM Time Series Forecasting\n",
    "\n",
    "## Plan:\n",
    "1. **Data Analysis**: Examine time series lengths and prepare for uniform processing\n",
    "2. **Dataset Creation**: Create sliding window sequences (6 months input → 1 month output)\n",
    "3. **Model Architecture**: Build LSTM model in PyTorch\n",
    "4. **Training Setup**: Configure train-test split, data loaders, and MPS device\n",
    "5. **Training**: Train single model across all time series\n",
    "6. **Evaluation**: Assess 1-month ahead forecast performance\n",
    "\n",
    "## Key Parameters:\n",
    "- Time series: 3,745 unique keys\n",
    "- Sequence length: 6 months (lookback)\n",
    "- Forecast horizon: 1 month ahead\n",
    "- Device: MPS (Apple Silicon GPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bc08c",
   "metadata": {},
   "source": [
    "## Step 1: Data Analysis and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6a3d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MPS device is available\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check MPS availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"✓ MPS device is available\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"✓ CUDA device is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using CPU\")\n",
    "    \n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87742094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesDataset class defined\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for time series with sliding window approach.\n",
    "    Each sample: [y(t-6), y(t-5), ..., y(t-1)] -> y(t)\n",
    "    \"\"\"\n",
    "    def __init__(self, df, seq_length=6, train=True, train_ratio=0.8):\n",
    "        self.seq_length = seq_length\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.ts_keys = []\n",
    "        \n",
    "        # Group by time series key\n",
    "        grouped = df.sort_values('Date').groupby('ts_key')\n",
    "        \n",
    "        for ts_key, group in grouped:\n",
    "            values = group['Value'].values\n",
    "            \n",
    "            # Skip if not enough data\n",
    "            if len(values) < seq_length + 1:\n",
    "                continue\n",
    "            \n",
    "            # Create sliding windows\n",
    "            for i in range(len(values) - seq_length):\n",
    "                self.X.append(values[i:i+seq_length])\n",
    "                self.y.append(values[i+seq_length])\n",
    "                self.ts_keys.append(ts_key)\n",
    "        \n",
    "        self.X = np.array(self.X, dtype=np.float32)\n",
    "        self.y = np.array(self.y, dtype=np.float32)\n",
    "        \n",
    "        # Train-test split\n",
    "        n_samples = len(self.X)\n",
    "        train_size = int(n_samples * train_ratio)\n",
    "        \n",
    "        if train:\n",
    "            self.X = self.X[:train_size]\n",
    "            self.y = self.y[:train_size]\n",
    "            self.ts_keys = self.ts_keys[:train_size]\n",
    "        else:\n",
    "            self.X = self.X[train_size:]\n",
    "            self.y = self.y[train_size:]\n",
    "            self.ts_keys = self.ts_keys[train_size:]\n",
    "        \n",
    "        # Standardize\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        \n",
    "        # Fit scaler on training data\n",
    "        if train:\n",
    "            self.X = self.scaler_X.fit_transform(self.X)\n",
    "            self.y = self.scaler_y.fit_transform(self.y.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            # For test set, we need the scaler from training\n",
    "            # This will be handled separately\n",
    "            pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.X[idx]).unsqueeze(-1), torch.FloatTensor([self.y[idx]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce3b185",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLSTMForecaster\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    LSTM model for univariate time series forecasting.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Architecture: LSTM -> Dropout -> LSTM -> Dropout -> Fully Connected\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size=\u001b[32m1\u001b[39m, hidden_size=\u001b[32m64\u001b[39m, num_layers=\u001b[32m2\u001b[39m, dropout=\u001b[32m0.2\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model for univariate time series forecasting.\n",
    "    Architecture: LSTM -> Dropout -> LSTM -> Dropout -> Fully Connected\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        super(LSTMForecaster, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_length, input_size)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Take the output from the last time step\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(last_output)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMForecaster(\n",
    "    input_size=1,\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model architecture:\\n{model}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec404fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "SEQ_LENGTH = 6  # 6 months lookback\n",
    "BATCH_SIZE = 256\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "print(\"Creating training dataset...\")\n",
    "train_dataset = TimeSeriesDataset(df, seq_length=SEQ_LENGTH, train=True, train_ratio=TRAIN_RATIO)\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "\n",
    "# Save scalers for test set\n",
    "scaler_X = train_dataset.scaler_X\n",
    "scaler_y = train_dataset.scaler_y\n",
    "\n",
    "print(\"\\nCreating test dataset...\")\n",
    "test_dataset = TimeSeriesDataset(df, seq_length=SEQ_LENGTH, train=False, train_ratio=TRAIN_RATIO)\n",
    "\n",
    "# Apply training scalers to test set\n",
    "test_dataset.X = scaler_X.transform(test_dataset.X)\n",
    "test_dataset.y = scaler_y.transform(test_dataset.y.reshape(-1, 1)).flatten()\n",
    "test_dataset.scaler_X = scaler_X\n",
    "test_dataset.scaler_y = scaler_y\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset):,}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "print(f\"\\nBatches per epoch: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"Training functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "print(f\"Starting training on {device}...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss = evaluate(model, test_loader, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), '../../models/best_lstm_model.pth')\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1:3d}/{EPOCHS}] | \"\n",
    "              f\"Train Loss: {train_loss:.6f} | \"\n",
    "              f\"Test Loss: {test_loss:.6f} | \"\n",
    "              f\"Time: {elapsed:.1f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training completed in {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
    "print(f\"Best test loss: {best_test_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a46c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics on test set\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('../../models/best_lstm_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        predictions = model(X_batch)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_actuals.extend(y_batch.numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_predictions = np.array(all_predictions).flatten()\n",
    "all_actuals = np.array(all_actuals).flatten()\n",
    "\n",
    "# Inverse transform to original scale\n",
    "all_predictions_original = scaler_y.inverse_transform(all_predictions.reshape(-1, 1)).flatten()\n",
    "all_actuals_original = scaler_y.inverse_transform(all_actuals.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(all_actuals_original, all_predictions_original)\n",
    "rmse = np.sqrt(mean_squared_error(all_actuals_original, all_predictions_original))\n",
    "mape = np.mean(np.abs((all_actuals_original - all_predictions_original) / (all_actuals_original + 1e-8))) * 100\n",
    "r2 = r2_score(all_actuals_original, all_predictions_original)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL PERFORMANCE METRICS (Original Scale)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean Absolute Error (MAE):        {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):   {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error:   {mape:.2f}%\")\n",
    "print(f\"R² Score:                         {r2:.4f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416e735",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Model Configuration:**\n",
    "- Architecture: 2-layer LSTM with 64 hidden units\n",
    "- Input: 6-month sliding window\n",
    "- Output: 1-month ahead forecast\n",
    "- Training on MPS (Apple Silicon GPU)\n",
    "- Single model trained across all 3,745 time series\n",
    "\n",
    "**Key Features:**\n",
    "- Standardized input/output using StandardScaler\n",
    "- Dropout (0.2) for regularization\n",
    "- Gradient clipping to prevent exploding gradients\n",
    "- Learning rate scheduling with ReduceLROnPlateau\n",
    "- 80/20 train-test split\n",
    "\n",
    "**Next Steps:**\n",
    "1. Experiment with different sequence lengths\n",
    "2. Try multivariate approach with exogenous variables\n",
    "3. Compare with other architectures (GRU, Transformer)\n",
    "4. Implement per-time-series evaluation\n",
    "5. Analyze performance by OEM/powertrain type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Predictions vs Actuals\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(all_actuals_original, all_predictions_original, alpha=0.3, s=10)\n",
    "axes[0].plot([all_actuals_original.min(), all_actuals_original.max()], \n",
    "             [all_actuals_original.min(), all_actuals_original.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Values', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Values', fontsize=12)\n",
    "axes[0].set_title('Predictions vs Actuals (All Time Series)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = all_actuals_original - all_predictions_original\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals (Actual - Predicted)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Residual Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.2f}\")\n",
    "print(f\"  Std: {residuals.std():.2f}\")\n",
    "print(f\"  Min: {residuals.min():.2f}\")\n",
    "print(f\"  Max: {residuals.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "\n",
    "ax.plot(train_losses, label='Training Loss', linewidth=2)\n",
    "ax.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "ax.set_title('LSTM Training History - All Time Series', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final Test Loss: {test_losses[-1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace1fad",
   "metadata": {},
   "source": [
    "## Step 6: Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Optimizer: Adam\")\n",
    "print(f\"  Loss function: MSE\")\n",
    "print(f\"  Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c579afd",
   "metadata": {},
   "source": [
    "## Step 5: Training Setup and Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7a7bb",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27140f0f",
   "metadata": {},
   "source": [
    "## Step 3: Define LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf628e8",
   "metadata": {},
   "source": [
    "## Step 2: Create Sliding Window Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze time series lengths\n",
    "ts_lengths = df.groupby('ts_key').size()\n",
    "print(f\"Total time series: {df.ts_key.nunique()}\")\n",
    "print(f\"\\nTime series length statistics:\")\n",
    "print(ts_lengths.describe())\n",
    "print(f\"\\nMinimum length: {ts_lengths.min()}\")\n",
    "print(f\"Maximum length: {ts_lengths.max()}\")\n",
    "\n",
    "# Check how many series have at least 7 observations (needed for 6-month lookback + 1 target)\n",
    "min_required = 7\n",
    "valid_series = (ts_lengths >= min_required).sum()\n",
    "print(f\"\\nTime series with >= {min_required} observations: {valid_series} / {len(ts_lengths)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
