{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will implement the RNN Model Recurrent Neural Network. \n",
    "\n",
    "The RNN (Recurrent Neural Network) Forecaster is a vanilla RNN model designed for multivariate time series forecasting. It processes sequential data using recurrent connections that maintain a hidden state across time steps.\n",
    "\n",
    "Layer Breakdown:\n",
    "\n",
    "- **RNN Layers:** 2 stacked RNN layers with Tanh activation\n",
    "- **Hidden Size:** 64 units per layer\n",
    "- **Dropout:** Applied between RNN layers (if >1 layer) and before final output\n",
    "- **Output Layer:** Single fully connected layer producing 1-step forecast\n",
    "\n",
    "**Advantages**\n",
    "- **Simplicity:** Simpler architecture than LSTM/GRU (only hidden state, no cell state)\n",
    "- **Speed:** Faster training due to fewer parameters\n",
    "- **Sequential Processing:** Captures temporal dependencies in time series data\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "- **Vanishing Gradients:** May struggle with long-term dependencies (sequences >10-20 steps)\n",
    "- **Limited Memory:** No gating mechanisms to control information flow like LSTM/GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNForecaster(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla RNN model for MULTIVARIATE time series forecasting.\n",
    "    Architecture: RNN -> Dropout -> RNN -> Dropout -> Fully Connected\n",
    "    Takes multiple input features at each timestep.\n",
    "    \n",
    "    Simpler than LSTM - no cell state, only hidden state.\n",
    "    Faster training but may struggle with long-term dependencies.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size: Number of input features (Value + year + month + one-hot)\n",
    "            hidden_size: RNN hidden dimension\n",
    "            num_layers: Number of RNN layers\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super(RNNForecaster, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # RNN layers (using Tanh activation by default)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            nonlinearity='tanh'  # Can also use 'relu'\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_length, input_size)\n",
    "        \n",
    "        # RNN forward pass\n",
    "        # rnn_out: (batch_size, seq_length, hidden_size)\n",
    "        # h_n: (num_layers, batch_size, hidden_size)\n",
    "        rnn_out, h_n = self.rnn(x)\n",
    "        \n",
    "        # Take the output from the last time step\n",
    "        last_output = rnn_out[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "        \n",
    "        # Apply dropout\n",
    "        out = self.dropout(last_output)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MPS device is available\n",
      "Device: mps\n",
      "================================================================================\n",
      "DATA OVERVIEW\n",
      "================================================================================\n",
      "Original data shape: (107922, 29)\n",
      "Unique time series: 1502\n",
      "Date range: 2018-01-31 00:00:00 to 2025-09-30 00:00:00\n",
      "Total observations: 107,922\n",
      "\n",
      "Original DataFrame:\n",
      "  NaN values: 0\n",
      "  Inf values: 0\n",
      "  Value range: [0.00, 22335.00]\n",
      "\n",
      "Zero values in 'Value' column: 20818\n",
      "Values < 0.01: 20818\n",
      "\n",
      "================================================================================\n",
      "FOLD CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Fold 1:\n",
      "  Training data: up to 2024-09-30\n",
      "  Test period: 2024-10-01 to 2024-12-31\n",
      "\n",
      "Fold 2:\n",
      "  Training data: up to 2024-12-31\n",
      "  Test period: 2025-01-01 to 2025-03-31\n",
      "\n",
      "Fold 3:\n",
      "  Training data: up to 2025-06-30\n",
      "  Test period: 2025-07-01 to 2025-09-30\n",
      "\n",
      "================================================================================\n",
      "FOLD 1: 2024-10-01 to 2024-12-31\n",
      "================================================================================\n",
      "\n",
      "Filtered training data up to 2024-09-30\n",
      "  Training observations: 90,494\n",
      "  Date range: 2018-01-31 00:00:00 to 2024-09-30 00:00:00\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 1: Creating datasets for model development\n",
      "------------------------------------------------------------\n",
      "Creating dataset with 1478 time series...\n",
      "Additional features: 26\n",
      "Sequence length: 6, Embargo: 1\n",
      "Created 80408 samples with feature dimension: 1507\n",
      "  - Value: 1\n",
      "  - Additional features: 26\n",
      "  - Temporal (year, month): 2\n",
      "  - One-hot ts_key: 1478\n",
      "Training samples: 64,326\n",
      "Creating dataset with 1478 time series...\n",
      "Additional features: 26\n",
      "Sequence length: 6, Embargo: 1\n",
      "Created 80408 samples with feature dimension: 1507\n",
      "  - Value: 1\n",
      "  - Additional features: 26\n",
      "  - Temporal (year, month): 2\n",
      "  - One-hot ts_key: 1478\n",
      "Validation samples: 16,082\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 2: Training RNN model\n",
      "------------------------------------------------------------\n",
      "Model parameters: 109,057\n",
      "Epoch [  1/50] | Train: 0.206289 | Val: 1.255152 | Time: 6.7s\n",
      "Epoch [ 10/50] | Train: 0.122730 | Val: 1.313018 | Time: 67.0s\n",
      "Epoch [ 20/50] | Train: 0.100452 | Val: 1.171646 | Time: 132.6s\n",
      "Epoch [ 30/50] | Train: 0.092931 | Val: 1.133936 | Time: 198.8s\n",
      "Epoch [ 40/50] | Train: 0.089149 | Val: 1.132690 | Time: 263.5s\n",
      "Epoch [ 50/50] | Train: 0.088180 | Val: 1.145377 | Time: 328.5s\n",
      "\n",
      "Training completed in 328.5s\n",
      "Best validation loss: 1.090148\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 3: Out-of-sample predictions (OPTIMIZED)\n",
      "------------------------------------------------------------\n",
      "Test period: 2024-10-01 to 2024-12-31\n",
      "Test observations: 4,364\n",
      "Processing 1319 time series in batched mode...\n",
      "Generated predictions for 1319 time series\n",
      "Total predictions: 3,957\n",
      "Optimization: 3957 individual predictions → 3 batched forward passes\n",
      "✓ Saved predictions to: predictions.csv (3957 rows)\n",
      "\n",
      "SMAPE Distribution for Fold 1:\n",
      "  Time series evaluated: 1319\n",
      "        <10%:  147 series ( 11.1%)\n",
      "      10-20%:   45 series (  3.4%)\n",
      "      20-30%:   74 series (  5.6%)\n",
      "      30-40%:   84 series (  6.4%)\n",
      "        >40%:  969 series ( 73.5%)\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 4: Evaluation Metrics\n",
      "------------------------------------------------------------\n",
      "\n",
      "Fold 1 Out-of-Sample Metrics:\n",
      "  MSE:   112910.40\n",
      "  RMSE:  336.02\n",
      "  MAE:   151.90\n",
      "  R²:    0.7976\n",
      "  SMAPE: 102.29%\n",
      "\n",
      "================================================================================\n",
      "FOLD 2: 2025-01-01 to 2025-03-31\n",
      "================================================================================\n",
      "\n",
      "Filtered training data up to 2024-12-31\n",
      "  Training observations: 94,858\n",
      "  Date range: 2018-01-31 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 1: Creating datasets for model development\n",
      "------------------------------------------------------------\n",
      "Creating dataset with 1502 time series...\n",
      "Additional features: 26\n",
      "Sequence length: 6, Embargo: 1\n",
      "Created 84537 samples with feature dimension: 1531\n",
      "  - Value: 1\n",
      "  - Additional features: 26\n",
      "  - Temporal (year, month): 2\n",
      "  - One-hot ts_key: 1502\n",
      "Training samples: 67,629\n",
      "Creating dataset with 1502 time series...\n",
      "Additional features: 26\n",
      "Sequence length: 6, Embargo: 1\n",
      "Created 84537 samples with feature dimension: 1531\n",
      "  - Value: 1\n",
      "  - Additional features: 26\n",
      "  - Temporal (year, month): 2\n",
      "  - One-hot ts_key: 1502\n",
      "Validation samples: 16,908\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 2: Training RNN model\n",
      "------------------------------------------------------------\n",
      "Model parameters: 110,593\n",
      "Epoch [  1/50] | Train: 0.195967 | Val: 1.236318 | Time: 7.0s\n",
      "Epoch [ 10/50] | Train: 0.123355 | Val: 1.094195 | Time: 70.9s\n",
      "Epoch [ 20/50] | Train: 0.104588 | Val: 1.186845 | Time: 141.9s\n",
      "Epoch [ 30/50] | Train: 0.091813 | Val: 1.155223 | Time: 212.3s\n",
      "Epoch [ 40/50] | Train: 0.089263 | Val: 1.158984 | Time: 281.9s\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd ..&& python ./neuralts/main.py --model RNN --epochs 25 --batch-size 64 --learning-rate 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
